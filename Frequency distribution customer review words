import pandas as pd
from collections import Counter
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

nltk.download('punkt')
nltk.download('stopwords')

data = {
    'review_id': [1, 2, 3, 4, 5],
    'review_text': [
        "This product is great! I really like it.",
        "Not what I expected, very disappointed.",
        "Excellent quality, will buy again.",
        "Terrible product. Do not buy!",
        "Good value for money."
    ]
}

df = pd.DataFrame(data)

stop_words = set(stopwords.words('english'))
punctuations = set(string.punctuation)

def preprocess_text(text):
    words = word_tokenize(text.lower())
    filtered_words = [word for word in words if word not in stop_words and word not in punctuations]
    return filtered_words

df['processed_text'] = df['review_text'].apply(preprocess_text)

all_words = [word for review in df['processed_text'] for word in review]
word_freq = Counter(all_words)

print("Frequency distribution of words:")
print(word_freq)
